{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b5865-b35e-4a2d-bf9f-e5f3ccb7ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066b6336-a425-4dac-b1d7-2d4164c39e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 13:54:05.042072: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 13:54:06.023736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`speechbrain` was not imported\n",
      "`LEAF` was not imported\n",
      "colorednoise package is missing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import h5py\n",
    "import onnxruntime as ort\n",
    "import openvino as ov\n",
    "import tensorflow_hub as hub\n",
    "import torch.quantization.quantize_fx as quantize_fx\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "from os.path import join as pjoin\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import f1_score \n",
    "from scipy.special import expit\n",
    "\n",
    "# from code_base.utils import parallel_librosa_load, groupby_np_array, stack_and_max_by_samples, macro_f1_similarity, N_CLASSES_2021_2022, N_CLASSES_2021, comp_metric, N_CLASSES_XC_LIGIT_SHORTEN, N_CLASSES_XC_LIGIT_EVEN_SHORTEN\n",
    "# from code_base.utils.constants import SAMPLE_RATE\n",
    "from code_base.utils.onnx_utils import ONNXEnsemble, convert_to_onnx\n",
    "from code_base.models import WaveCNNClasifier, WaveCNNAttenClasifier, WaveTDNNClasifier\n",
    "from code_base.datasets import WaveDataset, WaveAllFileDataset\n",
    "from code_base.utils.swa import avarage_weights, delete_prefix_from_chkp\n",
    "from code_base.inefernce import BirdsInference\n",
    "from code_base.utils import load_json, compose_submission_dataframe, groupby_np_array, stack_and_max_by_samples, write_json\n",
    "from code_base.utils.metrics import score_numpy\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737b54a-20f3-40b4-893c-018539b384b3",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3bbb24-b29e-4183-985b-22f935ff32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"https://www.kaggle.com/models/google/bird-vocalization-classifier/TensorFlow2/bird-vocalization-classifier/8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72915839-edd3-43d2-a51d-bbc70fd3e342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7717,  4041,   354,  4914,  1643,  5186,  4749,  4621,  2750,\n",
       "        1017,  1802,  4524,  3890,  7289,  8703,  6664,  7355,  9680,\n",
       "       10237,  1372,  4096,  5373,  6389,  5418,  2593,  4402,  4003,\n",
       "        6925,  3922, 10533,  7725,  1507,  5486,  8873,  7804,  4250,\n",
       "        5572,   901,  3624,  1031,  2707,  4791,  4609,  1692,  1016,\n",
       "        5120,   971, 10611,  2881,  3825,  6772,  4489,  1297,  1661,\n",
       "        7352,  9047,  2607,  1788,  8236,  6933,  4728,  6906,  5039,\n",
       "        4579,  2623,  5385, 10065,  7167,   967, 10050,  4522,  7359,\n",
       "        4754,  4942,  7436,  2598,  5235,  2601,   727,  3913,  6921,\n",
       "        8530,  6725,  5975,  8832,  4611,  5047,  4174,  9961,   990,\n",
       "        8029,  6260,  1594,  6649,  3792,  3462,  9378,  5145,  4076,\n",
       "        1964,  6922,  4623,  4602,  2524,  6315,  2815,  7666,  5718,\n",
       "        9836,  4753,   362,  5982,  2103,  9888,  2898,  9422,  6268,\n",
       "        5148,  1600,  7998,   577,  2627, 10584,  5409,  4618,  4794,\n",
       "        8784,  3697,  7476,  4855,   326,   364,  6823, 10056,  3218,\n",
       "        4603,  4619,  3894,  1417,  6726,  3221,   315,  2605,  2612,\n",
       "        2622,   600,  5097, 10031,  3904,  5417,  6068,   347,  3886,\n",
       "        4601,  3958,  9676,  1704,  1353,  8767, 10058,  2776,  4614,\n",
       "       10299,  2201,  5115,  4112,  4006,   337,  4636,  6271,  2599,\n",
       "        6736,  3176,   360, 10077,  1715,  2643, 10928,  9408,  3551,\n",
       "       10377,   366,  1789, 10620,  3207,  3126,  7483,  8444])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird2id_source = {\n",
    "    v:k for k,v in pd.read_csv(hub.resolve(MODEL_PATH) + \"/assets/label.csv\")[\"ebird2021\"].to_dict().items()\n",
    "}\n",
    "bird2id_source[\"bkrfla1\"] = bird2id_source.pop(\"bkrfla2\")\n",
    "bird2id_source[\"indrol2\"] = bird2id_source.pop(\"indrol1\")\n",
    "\n",
    "bird2id_target = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024.json\")\n",
    "\n",
    "\n",
    "id2bird_source = {v:k for k,v in bird2id_source.items()}\n",
    "id2bird_target = {v:k for k,v in bird2id_target.items()}\n",
    "\n",
    "REARRANGE_INDICES = np.array([\n",
    "    bird2id_source[id2bird_target[i]] for i in range(len(id2bird_target)) #if id2bird_target[i] not in ('bkrfla1', 'indrol2')\n",
    "]).astype(int)\n",
    "REARRANGE_INDICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e81f417-8370-4a68-85e7-89b47ab1e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Main\n",
    "    \"run_validation\": True,\n",
    "    \"run_test\": True,\n",
    "    # Inference Class\n",
    "    \"use_sigmoid\": False,\n",
    "    \"use_compiled_fp16\": False,\n",
    "    \"aggregate_preds\": True,\n",
    "    # Data config\n",
    "    \"train_df_path\": \"/home/vova/data/exps/birdclef_2024/birdclef_2024/train_metadata_extended_noduplv1.csv\",\n",
    "    \"split_path\": \"/home/vova/data/exps/birdclef_2024/cv_splits/birdclef_2024_5_folds_split_nodupl.npy\",\n",
    "    \"train_data_root\":\"/home/vova/data/exps/birdclef_2024/birdclef_2024/train_audio/\",\n",
    "    \"test_data_root\":\"/home/vova/data/exps/birdclef_2024/birdclef_2024/unlabeled_soundscapes/*.ogg\",\n",
    "    \"label_map_data_path\": \"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024.json\",\n",
    "    \"scored_birds_path\":\"/home/vova/data/exps/birdclef_2024/scored_birds/sb_2024.json\", \n",
    "    \"lookback\":None,\n",
    "    \"lookahead\":None,\n",
    "    \"segment_len\":5,\n",
    "    \"step\": None,\n",
    "    \"late_normalize\": False,\n",
    "    \n",
    "    \"model_output_key\": None,\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51829533-f273-4a67-9260-cd764da76f6d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff85dcc-47fd-4bed-beb3-fa4effb9236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird2id = load_json(CONFIG[\"label_map_data_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32a5c62-d255-4175-9da5-3787e8960a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    val_df = [pd.read_csv(CONFIG[\"train_df_path\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec62a903-a970-44a7-a61e-cefdf94f8b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2934077/715364531.py:6: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  \"duration_s\": [librosa.get_duration(filename=el) for el in test_au_pathes]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    test_au_pathes = glob(CONFIG[\"test_data_root\"])[:20]\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        \"filename\": test_au_pathes,\n",
    "        \"duration_s\": [librosa.get_duration(filename=el) for el in test_au_pathes]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be608001-f361-4fab-a7af-d69c224a38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    val_ds_conig = {\n",
    "       \"root\": CONFIG[\"train_data_root\"],\n",
    "       \"label_str2int_mapping_path\": CONFIG[\"label_map_data_path\"],\n",
    "       \"use_audio_cache\": True,\n",
    "       \"n_cores\": 64,\n",
    "       \"verbose\": False,\n",
    "       \"segment_len\": CONFIG[\"segment_len\"],\n",
    "       \"lookback\":CONFIG[\"lookback\"],\n",
    "       \"lookahead\":CONFIG[\"lookahead\"],\n",
    "       \"sample_id\": None,\n",
    "       \"late_normalize\": CONFIG[\"late_normalize\"],\n",
    "       \"load_normalize\": CONFIG.get(\"load_normalize\", False),\n",
    "       \"step\": CONFIG[\"step\"],\n",
    "        \"validate_sr\": 32_000\n",
    "    }\n",
    "if CONFIG[\"run_test\"]:\n",
    "    ds_config_test = {\n",
    "       \"root\": \"\",\n",
    "       \"label_str2int_mapping_path\": CONFIG[\"label_map_data_path\"],\n",
    "       \"n_cores\": 64,\n",
    "       \"use_audio_cache\": True,\n",
    "       \"test_mode\": True,\n",
    "       \"segment_len\": CONFIG[\"segment_len\"],\n",
    "       \"lookback\":CONFIG[\"lookback\"],\n",
    "       \"lookahead\":CONFIG[\"lookahead\"],\n",
    "        \"sample_id\": None,\n",
    "        \"late_normalize\": CONFIG[\"late_normalize\"],\n",
    "        \"load_normalize\": CONFIG.get(\"load_normalize\", False),\n",
    "        \"step\": CONFIG[\"step\"],\n",
    "        \"validate_sr\": 32_000\n",
    "    }\n",
    "loader_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"drop_last\": False,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9014d6e6-56e9-45d6-9dcf-c76c4f59bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secondary_labels is not found in df. Maybe test or nocall mode\n"
     ]
    }
   ],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    ds_test = WaveAllFileDataset(df=test_df, **ds_config_test)\n",
    "if CONFIG[\"run_validation\"]:\n",
    "    ds_val = [WaveAllFileDataset(df=df, **val_ds_conig) for df in val_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01310c22-1f3d-45a0-a8c8-1dae95b0c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    loader_val = [torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        **loader_config,\n",
    "    )for ds in ds_val]\n",
    "if CONFIG[\"run_test\"]:\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        ds_test,\n",
    "        **loader_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc85eee-c91b-408f-b1e6-a6ea47dacfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf70ba-989d-4c39-b97b-473e2b69c72f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eca2d30-3563-4da6-8ce2-f9735bab22d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 13:54:15.212657: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = hub.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72379cff-f673-4020-8105-41607cf68107",
   "metadata": {},
   "source": [
    "# Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c17c1f-7efe-41e6-9a2e-3285c81ef740",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_class = BirdsInference(\n",
    "    device=\"cpu\",\n",
    "    verbose_tqdm=True,\n",
    "    use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "    model_output_key=CONFIG[\"model_output_key\"],\n",
    "    aggregate_preds=CONFIG.get(\"aggregate_preds\", True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ffa25b3-c61c-42c7-bab8-1e761ee794b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_class.use_sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6bcf9a-e43d-4fe5-8228-0579b6a27240",
   "metadata": {},
   "source": [
    "# Val Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13939bdb-8fb1-4e72-8d60-b6eaf7e39ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                              | 0/3389 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714312470.051506 2934077 service.cc:145] XLA service 0x5aee32298a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714312470.051556 2934077 service.cc:153]   StreamExecutor device (0): Host, Default Version\n",
      "2024-04-28 13:54:30.322634: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1714312470.332707 2934077 assert_op.cc:38] Ignoring Assert operator jax2tf_infer_fn_/assert_equal_1/Assert/AssertGuard/Assert\n",
      "I0000 00:00:1714312472.745816 2934077 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "  4%|██████▉                                                                                                                                                        | 147/3389 [1:07:27<24:28:19, 27.17s/it]"
     ]
    }
   ],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    val_tgts, val_preds = inference_class.predict_val_loaders(\n",
    "        nn_models=[model],\n",
    "        data_loaders=loader_val,\n",
    "        is_google_model=True,\n",
    "        google_postprocess=lambda x: expit(x[\"label\"].numpy())[:,REARRANGE_INDICES]\n",
    "    )\n",
    "    if CONFIG.get(\"scored_birds_path\", None):\n",
    "        print(\"Extracting scored_bird_ids indices\")\n",
    "        scored_bird = load_json(CONFIG[\"scored_birds_path\"])\n",
    "        scored_bird_ids = [bird2id[el] for el in scored_bird]\n",
    "        val_tgts = [el[:,scored_bird_ids] for el in val_tgts]\n",
    "        val_preds = [el[:,scored_bird_ids] for el in val_preds]\n",
    "    cmaps = [\n",
    "        score_numpy(gt, pr) for gt, pr in zip(val_tgts, val_preds)\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        f\"Folds Roc Auc: {cmaps}\\n\"\n",
    "        f\"Mean Roc Auc: {np.mean(cmaps)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ab37f-43dc-4b89-a547-681617b3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Folds Roc Auc: {cmaps}\\n\"\n",
    "    f\"Mean Roc Auc: {np.mean(cmaps)}\\n\"\n",
    "    f\"OOF Roc Auc: {score_numpy(np.concatenate(val_tgts), np.concatenate(val_preds))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d7354-942b-4c2f-835a-884bf0d1dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds[0].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f1cfc-1fee-49a3-8330-1f9d5e1e7906",
   "metadata": {},
   "source": [
    "```\n",
    "Full Checkpoint\n",
    "\n",
    "Folds Roc Auc: [0.9821510023950407]\n",
    "Mean Roc Auc: 0.9821510023950407\n",
    "OOF Roc Auc: 0.9821510023950407\n",
    "\n",
    "Openvino FP16\n",
    "\n",
    "Folds Roc Auc: [0.9813698940740585]\n",
    "Mean Roc Auc: 0.9813698940740585\n",
    "OOF Roc Auc: 0.9813698940740585\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7235f5-1e7f-4e0d-9568-78dda18d164a",
   "metadata": {},
   "source": [
    "# Search for Pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314297ea-fd7e-4948-99f9-af98588f41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_tgts = np.concatenate(val_tgts)\n",
    "all_val_preds = np.concatenate(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf9f77-d734-453a-a234-c7ca704c73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_treshes = np.arange(0.05 , 1.0 + 0.05, 0.05)\n",
    "all_scores = []\n",
    "for tresh in tqdm(all_treshes):\n",
    "    all_scores.append(f1_score(\n",
    "        all_val_tgts,\n",
    "        all_val_preds > tresh,\n",
    "        average=\"macro\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55f1fc-664a-4e0d-a615-ae0ec1d1a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(all_scores)\n",
    "best_tresh, best_score = all_treshes[best_idx], all_scores[best_idx]\n",
    "\n",
    "print(f\"Best Score = {best_score} and is reached on {best_tresh}\")\n",
    "\n",
    "plt.title(\"Macro F1 depending on tresh\")\n",
    "plt.plot(all_treshes, all_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7f5ca-909e-48b8-acf6-d2cacb136637",
   "metadata": {},
   "source": [
    "# Test Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab776f-b726-4633-a26e-ea3f85a75db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    test_preds, test_preds_long, test_dfidx, test_end = inference_class.predict_test_loader(\n",
    "        nn_models=model,\n",
    "        data_loader=loader_test\n",
    "    )\n",
    "    test_pred_df = compose_submission_dataframe(\n",
    "        probs=test_preds,\n",
    "        dfidxs=test_dfidx,\n",
    "        end_seconds=test_end,\n",
    "        filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "        bird2id=bird2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073afb3-6e5b-4a40-9b26-de6fa8ed6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd7503-e5c9-4169-8e81-6854db7b9b4d",
   "metadata": {},
   "source": [
    "# ONNX Test Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa5859-ff95-4efe-a50e-9b91dfe7175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_class_onnx = BirdsInference(\n",
    "    device=\"cpu\",\n",
    "    verbose_tqdm=True,\n",
    "    use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "    model_output_key=CONFIG[\"model_output_key\"],\n",
    "    use_compiled_fp16=CONFIG[\"use_compiled_fp16\"],\n",
    ")\n",
    "# onnx_model = ort.InferenceSession(\n",
    "#     # f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_2first_folds/model_simpl.onnx\"\n",
    "#     \"../logdirs/convnext_small_fb_in22k_ft_in1k_384_Exp_noamp_64bs_5sec_mixupP05_RandomFiltering_balancedSampler_Radamlr1e4_CosBatchLR1e6_Epoch50_SpecAugV1_FocalLoss_Full/onnx_ensem/model_simpl.onnx\"\n",
    "# )\n",
    "# core = ov.Core()\n",
    "# model = core.read_model(model=f\"../logdirs/convnext_small_fb_in22k_ft_in1k_384_Exp_noamp_64bs_5sec_mixupP05_RandomFiltering_balancedSampler_Radamlr1e4_CosBatchLR1e6_Epoch50_SpecAugV1_FocalLoss_Full/openvino_ensem/model_simpl.xml\")\n",
    "# compiled_model = core.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6e56f-e08d-4611-80ec-013b315968fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_onnx, test_dfidx_onnx, test_end_onnx = inference_class_onnx.predict_test_loader(\n",
    "    nn_models=compiled_model,\n",
    "    data_loader=loader_test,\n",
    "    is_openvino_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89962ccb-280f-4513-8eb1-e95c8535675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx = compose_submission_dataframe(\n",
    "    probs=test_preds_onnx,\n",
    "    dfidxs=test_dfidx_onnx,\n",
    "    end_seconds=test_end_onnx,\n",
    "    filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "    bird2id=bird2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7d0a8-1bc1-4eff-918c-905c8f574113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61965eb3-77f9-4f1f-a2df-f7c034e3cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx_fp16 = pd.read_csv(\"temp_fp16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00072a23-bc88-415d-989d-64d22c7932aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx_fp16.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d7026-a2e5-461f-842d-fefd51612b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(test_pred_df_onnx_fp16.iloc[:,1:].values - test_pred_df_onnx.iloc[:,1:].values).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b97df7-6c6d-4c2d-bd3e-90a663574320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_df_onnx.to_csv(\"temp_fp16.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ad67f-4c65-4cc1-84fe-e341ad7e4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_pred_df_onnx.iloc[:,1:].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3139ea0-58f7-4bc9-aa1f-28209387db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    inference_class_onnx = BirdsInference(\n",
    "        device=\"cpu\",\n",
    "        verbose_tqdm=True,\n",
    "        use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "        model_output_key=CONFIG[\"model_output_key\"],\n",
    "        \n",
    "    )\n",
    "    onnx_model = ort.InferenceSession(\n",
    "        f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_2first_folds/model_simpl.onnx\"\n",
    "    )\n",
    "    test_preds_onnx, test_preds_long_onnx, test_dfidx_onnx, test_end_onnx = inference_class_onnx.predict_test_loader(\n",
    "        nn_models=onnx_model,\n",
    "        data_loader=loader_test,\n",
    "        is_onnx_model=True\n",
    "    )\n",
    "    test_pred_df_onnx = compose_submission_dataframe(\n",
    "        probs=test_preds_onnx,\n",
    "        dfidxs=test_dfidx_onnx,\n",
    "        end_seconds=test_end_onnx,\n",
    "        filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "        bird2id=bird2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fa245-3dbf-48c0-aacd-c5af2fa040be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84806a-be2d-442e-b132-f7bc8db644f0",
   "metadata": {},
   "source": [
    "# Map Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438a237-70d2-48c2-a9e5-32335718135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.get(\"check_inf_class\", False):\n",
    "    val_ds_check = WaveAllFileDataset(df=val_df[0], **{\n",
    "           \"root\": CONFIG[\"train_data_root\"],\n",
    "           \"label_str2int_mapping_path\": CONFIG[\"label_map_data_path\"],\n",
    "           \"n_cores\": 64,\n",
    "           \"use_audio_cache\": True,\n",
    "           \"test_mode\": True,\n",
    "           \"segment_len\": CONFIG[\"segment_len\"],\n",
    "           \"lookback\":CONFIG[\"lookback\"],\n",
    "           \"lookahead\":CONFIG[\"lookahead\"],\n",
    "            \"sample_id\": None,\n",
    "            \"late_normalize\": CONFIG[\"late_normalize\"],\n",
    "            \"step\": CONFIG[\"step\"],\n",
    "        }\n",
    "    )\n",
    "    val_loader_check = torch.utils.data.DataLoader(\n",
    "        val_ds_check,\n",
    "        **loader_config\n",
    "    )\n",
    "    \n",
    "    test_preds_check, test_preds_long_check, test_dfidx_check, test_end_check = inference_class.predict_test_loader(\n",
    "        nn_models=model,\n",
    "        data_loader=val_loader_check\n",
    "    )\n",
    "    test_preds_check_grouped = groupby_np_array(\n",
    "        groupby_f=test_dfidx_check,\n",
    "        array_to_group=test_preds_check,\n",
    "        apply_f=stack_and_max_by_samples,\n",
    "    )\n",
    "    print(np.allclose(\n",
    "        test_preds_check_grouped,\n",
    "        val_preds\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6d7a1-3079-4296-9f29-1ca6cae7506e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

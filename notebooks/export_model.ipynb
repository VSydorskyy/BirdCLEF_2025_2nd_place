{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac3599-7795-418b-8c0f-9cb6e8b23f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de71ce59-eafd-40f7-aacf-cb2b6c0f914a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`speechbrain` was not imported\n",
      "`LEAF` was not imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import h5py\n",
    "import onnxruntime as ort\n",
    "import openvino as ov\n",
    "import re\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "from os.path import join as pjoin\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "# from code_base.utils import parallel_librosa_load, groupby_np_array, stack_and_max_by_samples, macro_f1_similarity, N_CLASSES_2021_2022, N_CLASSES_2021, comp_metric, N_CLASSES_XC_LIGIT_SHORTEN, N_CLASSES_XC_LIGIT_EVEN_SHORTEN\n",
    "# from code_base.utils.constants import SAMPLE_RATE\n",
    "from code_base.utils.onnx_utils import ONNXEnsemble, convert_to_onnx\n",
    "from code_base.models import WaveCNNClasifier, WaveCNNAttenClasifier\n",
    "from code_base.datasets import WaveDataset, WaveAllFileDataset\n",
    "from code_base.utils.swa import avarage_weights, delete_prefix_from_chkp\n",
    "from code_base.inefernce import BirdsInference\n",
    "from code_base.utils import load_json, compose_submission_dataframe, groupby_np_array, stack_and_max_by_samples, write_json\n",
    "from code_base.utils.metrics import score_numpy\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbefe7e-9217-4b0e-8d8d-7b690038a69f",
   "metadata": {},
   "source": [
    "# Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606cef9-2299-44af-bf31-c0efe46ad739",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lt ../logdirs/ | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c8b749-45d8-4985-9649-96c42d7514c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird2id_source = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024_PrevComp.json\")\n",
    "bird2id_target = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024.json\")\n",
    "\n",
    "id2bird_source = {v:k for k,v in bird2id_source.items()}\n",
    "id2bird_target = {v:k for k,v in bird2id_target.items()}\n",
    "\n",
    "REARRANGE_INDICES = np.array([\n",
    "    bird2id_source[id2bird_target[i]] for i in range(len(id2bird_target))\n",
    "]).astype(int)\n",
    "\n",
    "MODEL_CLASS = WaveCNNAttenClasifier\n",
    "TRAIN_PERIOD = 5\n",
    "STRICT_LOAD = False\n",
    "\n",
    "def prune_checkpoint_rule(inp_chkp):\n",
    "    inp_chkp[\"head.attention.weight\"] = inp_chkp[\"head.attention.weight\"][REARRANGE_INDICES]\n",
    "    inp_chkp[\"head.attention.bias\"] = inp_chkp[\"head.attention.bias\"][REARRANGE_INDICES]\n",
    "    \n",
    "    inp_chkp[\"head.fix_scale.weight\"] = inp_chkp[\"head.fix_scale.weight\"][REARRANGE_INDICES]\n",
    "    inp_chkp[\"head.fix_scale.bias\"] = inp_chkp[\"head.fix_scale.bias\"][REARRANGE_INDICES]\n",
    "\n",
    "    return inp_chkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a6790a-22de-4508-a24b-8b5cad6deb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bird2id_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1293b406-e4dd-41db-82a4-6c40cc78f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible checkpoints:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXP_NAME = \"convnextv2_tiny_fcmae_ft_in22k_in1k_384_And_tf_efficientnetv2_b2_in1k_Pred075_Timewise025\"\n",
    "EXP_NAME = \"tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1\"\n",
    "TRAIN_PERIOD = 5\n",
    "print(\"Possible checkpoints:\\n\\n{}\".format(\"\\n\".join(set([os.path.basename(el) for el in glob(f\"../logdirs/{EXP_NAME}/checkpoints/*.ckpt\") if \"train\" not in os.path.basename(el)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663cbb4-ee61-456a-bbaa-ae7781f4d4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_path = glob(f\"../logdirs/{EXP_NAME}/code/*train_configs*.py\")\n",
    "assert len(conf_path) == 1\n",
    "conf_path = conf_path[0]\n",
    "!cat {conf_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46147957-77dc-44bf-928e-0fd92762a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    {\n",
    "        \"model_config\": dict(\n",
    "            # backbone=\"convnextv2_tiny.fcmae_ft_in22k_in1k_384\",\n",
    "            # backbone=\"tf_efficientnetv2_b2.in1k\",\n",
    "            # backbone=\"tf_efficientnetv2_b0.in1k\",\n",
    "            backbone=\"tf_efficientnetv2_b1.in1k\",\n",
    "            # backbone=\"eca_nfnet_l0\",\n",
    "            # add_backbone_config={\"drop_path_rate\": 0.2},\n",
    "            mel_spec_paramms={\n",
    "                \"sample_rate\": 32000,\n",
    "                \"n_mels\": 128,\n",
    "                \"f_min\": 20,\n",
    "                \"n_fft\": 2048,\n",
    "                \"hop_length\": 512,\n",
    "                \"normalized\": True,\n",
    "            },\n",
    "            head_config={\n",
    "                \"p\": 0.5,\n",
    "                \"num_class\": 188,\n",
    "                \"train_period\": TRAIN_PERIOD,\n",
    "                \"infer_period\": TRAIN_PERIOD,\n",
    "                \"output_type\": \"clipwise_pred_long\",\n",
    "            },\n",
    "            exportable=True,\n",
    "        ),\n",
    "        \"exp_name\": EXP_NAME,\n",
    "        #\"convnextv2_tiny_fcmae_ft_in22k_in1k_384_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_StrongBackGroundSoundScapeP075_StrongPinkOrGaus075_mixupP075Alpha1_RandomFiltering_balancedSampler_Radamlr1e4_CosBatchLR1e6_Epoch30_FocalLoss_Full_NoDuplsV1\",\n",
    "        \"fold\": None,\n",
    "        \"chkp_name\":\"last.ckpt\",\n",
    "        \"swa_checkpoint_regex\": None, #r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "        \"use_sigmoid\": True,\n",
    "        \"swa_sort_rule\": lambda x: -float(x[\"valid_roc_auc\"]),\n",
    "        \"delete_prefix\": \"model.\",\n",
    "        \"n_swa_models\": 1,\n",
    "        \"model_output_key\": None,\n",
    "        # \"prune_checkpoint_func\": prune_checkpoint_rule\n",
    "    },\n",
    "    # {\n",
    "    #     \"model_config\": dict(\n",
    "    #         backbone=\"maxvit_rmlp_pico_rw_256.sw_in1k\",\n",
    "    #         mel_spec_paramms={\n",
    "    #             \"sample_rate\": 32000,\n",
    "    #             \"n_mels\": 128,\n",
    "    #             \"f_min\": 20,\n",
    "    #             \"n_fft\": 2048,\n",
    "    #             \"hop_length\": 512,\n",
    "    #             \"normalized\": True,\n",
    "    #         },\n",
    "    #         spec_resize=(256,256),\n",
    "    #         spec_augment_config={\n",
    "    #             \"freq_mask\": {\n",
    "    #                 \"mask_max_length\": 10,\n",
    "    #                 \"mask_max_masks\": 3,\n",
    "    #                 \"p\": 0.3,\n",
    "    #                 \"inplace\": True,\n",
    "    #             },\n",
    "    #             \"time_mask\": {\n",
    "    #                 \"mask_max_length\": 20,\n",
    "    #                 \"mask_max_masks\": 3,\n",
    "    #                 \"p\": 0.3,\n",
    "    #                 \"inplace\": True,\n",
    "    #             },\n",
    "    #         },\n",
    "    #         atten_smoothing_config={\n",
    "    #             \"dropout\": 0.1,\n",
    "    #             \"num_layers\": 1,\n",
    "    #             \"n_steps\": 64,\n",
    "    #         },\n",
    "    #         head_type=\"AttHeadSimplified\",\n",
    "    #         head_config={\n",
    "    #             \"p\": 0.5,\n",
    "    #             \"num_class\": 188,\n",
    "    #             \"omit_pooling\": True,\n",
    "    #             \"output_type\": \"clipwise_pred_long\",\n",
    "    #         },\n",
    "    #         exportable=True,\n",
    "    #     ),\n",
    "    #     \"exp_name\": \"maxvit_rmlp_pico_rw_256_sw_in1k_Exp_FullAtten_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_BackGroundSoundScapeP05_mixupP05_RandomFiltering_balancedSampler_Radamlr3e4_CosBatchLR1e6_Epoch30_SpecAugV1_FocalLoss_Full_NoDuplsV1\",\n",
    "    #     \"fold\": None,\n",
    "    #     \"chkp_name\":\"last.ckpt\",\n",
    "    #     \"swa_checkpoint_regex\": None, #r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "    #     \"use_sigmoid\": True,\n",
    "    #     \"swa_sort_rule\": lambda x: -float(x[\"valid_tresh01_dice3d\"]),\n",
    "    #     \"delete_prefix\": \"model.\",\n",
    "    #     \"n_swa_models\": 3,\n",
    "    #     \"model_output_key\": None,\n",
    "    #     # \"prune_checkpoint_func\": prune_checkpoint_rule\n",
    "    # },\n",
    "    #  {\n",
    "    #     \"model_config\": dict(\n",
    "    #         backbone=\"tf_efficientnetv2_b2.in1k\",\n",
    "    #         mel_spec_paramms={\n",
    "    #             \"sample_rate\": 32000,\n",
    "    #             \"n_mels\": 128,\n",
    "    #             \"f_min\": 20,\n",
    "    #             \"n_fft\": 2048,\n",
    "    #             \"hop_length\": 512,\n",
    "    #             \"normalized\": True,\n",
    "    #         },\n",
    "    #         head_config={\n",
    "    #             \"p\": 0.5,\n",
    "    #             \"num_class\": 188,\n",
    "    #             \"train_period\": TRAIN_PERIOD,\n",
    "    #             \"infer_period\": TRAIN_PERIOD,\n",
    "    #             \"output_type\": \"clipwise_timewisemax_pred_short\",\n",
    "    #             \"infer_framewise_max_coef\": 0.25\n",
    "    #         },\n",
    "    #         exportable=True,\n",
    "    #     ),\n",
    "    #     \"exp_name\": \"tf_efficientnetv2_b2_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_BackGroundSoundScapeP05_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_Full_NoDuplsV1\",\n",
    "    #     \"fold\": None,\n",
    "    #     \"chkp_name\":\"last.ckpt\",\n",
    "    #     \"swa_checkpoint_regex\": None, #r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "    #     \"use_sigmoid\": True,\n",
    "    #     \"swa_sort_rule\": lambda x: -float(x[\"valid_tresh01_dice3d\"]),\n",
    "    #     \"delete_prefix\": \"model.\",\n",
    "    #     \"n_swa_models\": 3,\n",
    "    #     \"model_output_key\": None,\n",
    "    #     # \"prune_checkpoint_func\": prune_checkpoint_rule\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3cba2c8-e51d-49f0-8045-5c1ed7739b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_upload_chkp(\n",
    "    model_class,\n",
    "    model_config,\n",
    "    model_device,\n",
    "    model_chkp_root,\n",
    "    model_chkp_basename=None,\n",
    "    model_chkp_regex=None,\n",
    "    delete_prefix=None,\n",
    "    swa_sort_rule=None,\n",
    "    n_swa_to_take=3,\n",
    "    prune_checkpoint_func=None\n",
    "):\n",
    "    if model_chkp_basename is None:\n",
    "        basenames = os.listdir(model_chkp_root)\n",
    "        checkpoints = []\n",
    "        for el in basenames:\n",
    "            matches = re.findall(model_chkp_regex, el)\n",
    "            if not matches:\n",
    "                continue\n",
    "            parsed_dict = {key: value for key, value in matches}\n",
    "            parsed_dict[\"name\"] = el\n",
    "            checkpoints.append(parsed_dict)\n",
    "        print(\"SWA checkpoints\")\n",
    "        pprint(checkpoints)\n",
    "        checkpoints = sorted(checkpoints, key=swa_sort_rule)\n",
    "        checkpoints = checkpoints[:n_swa_to_take]\n",
    "        print(\"SWA sorted checkpoints\")\n",
    "        pprint(checkpoints)\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints = [\n",
    "                torch.load(os.path.join(model_chkp_root, el[\"name\"]), map_location=\"cpu\")[\"state_dict\"] for el in checkpoints\n",
    "            ]\n",
    "            t_chkp = avarage_weights(\n",
    "                nn_weights=checkpoints,\n",
    "                delete_prefix=delete_prefix\n",
    "            )\n",
    "        else:\n",
    "            chkp_path = os.path.join(model_chkp_root, checkpoints[0][\"name\"])\n",
    "            print(\"vanilla model\")\n",
    "            print(\"Loading\", chkp_path)\n",
    "            t_chkp = torch.load(\n",
    "                chkp_path, \n",
    "                map_location=\"cpu\"\n",
    "            )[\"state_dict\"]\n",
    "            if delete_prefix is not None:\n",
    "                t_chkp = delete_prefix_from_chkp(t_chkp, delete_prefix)\n",
    "    else:\n",
    "        chkp_path = os.path.join(model_chkp_root, model_chkp_basename)\n",
    "        print(\"vanilla model\")\n",
    "        print(\"Loading\", chkp_path)\n",
    "        t_chkp = torch.load(\n",
    "            chkp_path, \n",
    "            map_location=\"cpu\"\n",
    "        )[\"state_dict\"]\n",
    "        if delete_prefix is not None:\n",
    "            t_chkp = delete_prefix_from_chkp(t_chkp, delete_prefix)\n",
    "\n",
    "    if prune_checkpoint_func is not None:\n",
    "        t_chkp = prune_checkpoint_func(t_chkp)\n",
    "    t_model = model_class(**model_config, device=model_device) \n",
    "    print(\"Missing keys: \", set(t_model.state_dict().keys()) - set(t_chkp))\n",
    "    print(\"Extra keys: \",  set(t_chkp) - set(t_model.state_dict().keys()))\n",
    "    t_model.load_state_dict(t_chkp, strict=False)\n",
    "    t_model.eval()\n",
    "    return t_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06e3d64-a7af-44cf-9265-3f187a1eaf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = [create_model_and_upload_chkp(\n",
    "#     model_class=MODEL_CLASS,\n",
    "#     model_config=model_config['model_config'],\n",
    "#     model_device=\"cpu\",\n",
    "#     model_chkp_root=f\"../logdirs/{model_config['exp_name']}/checkpoints\",\n",
    "#     model_chkp_basename=model_config[\"chkp_name\"] if model_config[\"swa_checkpoint_regex\"] is None else None,\n",
    "#     model_chkp_regex=model_config.get(\"swa_checkpoint_regex\"),\n",
    "#     swa_sort_rule=model_config.get(\"swa_sort_rule\"),\n",
    "#     n_swa_to_take=model_config.get(\"n_swa_models\", 3),\n",
    "#     delete_prefix=model_config.get(\"delete_prefix\"),\n",
    "#     prune_checkpoint_func=model_config.get(\"prune_checkpoint_func\")\n",
    "# ) for model_config in MODELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fc7060-f499-41ee-93e2-725a9ac06a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla model\n",
      "Loading ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/fold_0/checkpoints/last.ckpt\n",
      "STFT kernels created, time used = 0.3047 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys:  set()\n",
      "Extra keys:  {'_forward.batch_aug.hann_window'}\n",
      "vanilla model\n",
      "Loading ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/fold_1/checkpoints/last.ckpt\n",
      "STFT kernels created, time used = 0.1195 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys:  set()\n",
      "Extra keys:  {'_forward.batch_aug.hann_window'}\n",
      "vanilla model\n",
      "Loading ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/fold_2/checkpoints/last.ckpt\n",
      "STFT kernels created, time used = 0.0947 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys:  set()\n",
      "Extra keys:  {'_forward.batch_aug.hann_window'}\n",
      "vanilla model\n",
      "Loading ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/fold_3/checkpoints/last.ckpt\n",
      "STFT kernels created, time used = 0.1196 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys:  set()\n",
      "Extra keys:  {'_forward.batch_aug.hann_window'}\n",
      "vanilla model\n",
      "Loading ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/fold_4/checkpoints/last.ckpt\n",
      "STFT kernels created, time used = 0.1376 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys:  set()\n",
      "Extra keys:  {'_forward.batch_aug.hann_window'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = [create_model_and_upload_chkp(\n",
    "    model_class=MODEL_CLASS,\n",
    "    model_config=MODELS[0]['model_config'],\n",
    "    model_device=\"cpu\",\n",
    "    model_chkp_root=f\"../logdirs/{MODELS[0]['exp_name']}/fold_{m_i}/checkpoints\",\n",
    "    # model_chkp_root=f\"../logdirs/{CONFIG['exp_name']}/checkpoints\",\n",
    "    model_chkp_basename=MODELS[0][\"chkp_name\"] if MODELS[0][\"swa_checkpoint_regex\"] is None else None,\n",
    "    model_chkp_regex=MODELS[0].get(\"swa_checkpoint_regex\"),\n",
    "    swa_sort_rule=MODELS[0].get(\"swa_sort_rule\"),\n",
    "    n_swa_to_take=MODELS[0].get(\"n_swa_models\", 3),\n",
    "    delete_prefix=MODELS[0].get(\"delete_prefix\"),\n",
    "    prune_checkpoint_func=MODELS[0].get(\"prune_checkpoint_func\")\n",
    ") for m_i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2142313a-73cf-4df7-843e-e98ad0e137d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.1334 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.0823 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.1184 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.1185 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.1207 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/nnAudio/features/stft.py:283: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.num_samples < self.pad_amount:\n",
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/backup/vova/src/exps/bird_clef_2024/.venv/lib/python3.11/site-packages/torch/onnx/utils.py:1209: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ONNX to OpenVINO\n",
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression by removing argument \"compress_to_fp16\" or set it to false \"compress_to_fp16=False\".\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "[ SUCCESS ] XML file: ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/onnx_ensem_logits_Last_openvino_fp16/model_simpl.xml\n",
      "[ SUCCESS ] BIN file: ../logdirs/tf_efficientnetv2_b1_in1k_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_mixupP05_RandomFiltering_balancedSampler_Radamlr1e3_CosBatchLR1e6_Epoch30_FocalLoss_5Folds_NoDuplsV1/onnx_ensem_logits_Last_openvino_fp16/model_simpl.bin\n"
     ]
    }
   ],
   "source": [
    "# exportable_ensem = ONNXEnsemble(\n",
    "#     model_class=MODEL_CLASS,\n",
    "#     configs=[deepcopy(config['model_config']) for config in MODELS],\n",
    "#     # final_activation=\"softmax\"\n",
    "#     # avarage_type=\"gaus\"\n",
    "#     # weights=[0.75,0.4,0.5]\n",
    "# )\n",
    "exportable_ensem = ONNXEnsemble(\n",
    "    model_class=MODEL_CLASS,\n",
    "    configs=[deepcopy(MODELS[0]['model_config']) for _ in range(5)],\n",
    "    # final_activation=\"softmax\"\n",
    "    # avarage_type=\"gaus\"\n",
    "    # weights=[0.75,0.4,0.5]\n",
    ")\n",
    "for model_id in range(len(exportable_ensem.models)):\n",
    "    exportable_ensem.models[model_id].load_state_dict(model[model_id].state_dict())\n",
    "exportable_ensem.eval()\n",
    "convert_to_onnx(\n",
    "    model_to_convert=exportable_ensem,\n",
    "    sample_input=torch.randn(5, TRAIN_PERIOD * 32_000),\n",
    "    base_path=f\"../logdirs/{EXP_NAME}/onnx_ensem_logits_Last\",\n",
    "    use_fp16=True,\n",
    "    use_openvino=True,\n",
    "    # opset_version=14\n",
    "    # base_path=\"test_onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec5a73-ded8-4532-99f8-b5727b670842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../logdirs/convnext_small_fb_in22k_ft_in1k_384__convnextv2_tiny_fcmae_ft_in22k_in1k_384__eca_nfnet_l0_noval_v27_075Clipwise025TimeMax_GausMean -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ea4bb-1236-4a9e-b8a2-6511c778bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../logdirs/convnext_small_fb_in22k_ft_in1k_384__convnextv2_tiny_fcmae_ft_in22k_in1k_384__eca_nfnet_l0_noval_v27_075Clipwise025TimeMax_GausMean -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b4ee8-ca40-4187-ad58-be7b6c4aee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lt ../logdirs/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e191dc-daa5-4aad-900c-99cb92470f40",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899cb74-eaff-4440-9825-d9c17ef714c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f\"../logdirs/{EXP_NAME}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f184826-0a01-43e1-a117-ce1223640bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "model = core.read_model(model=f\"../logdirs/{EXP_NAME}/onnx_ensem_openvino_fp16/model_simpl.xml\")\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b420c5b-10d3-416c-b8f1-372ae68fe070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randn(5, 32000*5).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4cbcb-0d72-440f-90a1-0786699bee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786d693-bc5c-46ca-ab13-61911edcf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = compiled_model([sample])[compiled_model.output(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff9e36-2c14-41df-832b-7d7c81dde53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db8867-3087-4dfd-9cbd-c7057bf55e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd7ea3-c0d3-4a51-b2e5-9326d266a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22496b86-f090-4527-8f8b-55a1088b9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = ort.InferenceSession(\n",
    "    f\"../logdirs/{EXP_NAME}/onnx_ensem_fp16/model_simpl.onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dede71-c5f1-4f10-858e-ac2dd87f7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = torch.from_numpy(np.random.randn(32000*5)).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a4073-e6ef-448b-8d6e-4a146dc0abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70a3d5-63d7-4304-b45d-5de7cb83befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out = onnx_model.run(\n",
    "    None,\n",
    "    {\"input\": sample}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35d2fe-0ea7-4fd8-ae8f-9e31e975763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7307a-c6b7-42e9-871c-4cb3b6a319a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    inference_class_onnx = BirdsInference(\n",
    "        device=\"cpu\",\n",
    "        verbose_tqdm=True,\n",
    "        use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "        model_output_key=CONFIG[\"model_output_key\"],\n",
    "    )\n",
    "    onnx_model = ort.InferenceSession(\n",
    "        f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_2first_folds/model_simpl.onnx\"\n",
    "    )\n",
    "    test_preds_onnx, test_preds_long_onnx, test_dfidx_onnx, test_end_onnx = inference_class_onnx.predict_test_loader(\n",
    "        nn_models=onnx_model,\n",
    "        data_loader=loader_test,\n",
    "        is_onnx_model=True\n",
    "    )\n",
    "    test_pred_df_onnx = compose_submission_dataframe(\n",
    "        probs=test_preds_onnx,\n",
    "        dfidxs=test_dfidx_onnx,\n",
    "        end_seconds=test_end_onnx,\n",
    "        filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "        bird2id=bird2id\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac3599-7795-418b-8c0f-9cb6e8b23f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71ce59-eafd-40f7-aacf-cb2b6c0f914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import h5py\n",
    "import onnxruntime as ort\n",
    "import openvino as ov\n",
    "import re\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "from os.path import join as pjoin\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "# from code_base.utils import parallel_librosa_load, groupby_np_array, stack_and_max_by_samples, macro_f1_similarity, N_CLASSES_2021_2022, N_CLASSES_2021, comp_metric, N_CLASSES_XC_LIGIT_SHORTEN, N_CLASSES_XC_LIGIT_EVEN_SHORTEN\n",
    "# from code_base.utils.constants import SAMPLE_RATE\n",
    "from code_base.utils.onnx_utils import ONNXEnsemble, convert_to_onnx\n",
    "from code_base.models import WaveCNNClasifier, WaveCNNAttenClasifier\n",
    "from code_base.datasets import WaveDataset, WaveAllFileDataset\n",
    "from code_base.utils.swa import avarage_weights, delete_prefix_from_chkp\n",
    "from code_base.inefernce import BirdsInference\n",
    "from code_base.utils import load_json, compose_submission_dataframe, groupby_np_array, stack_and_max_by_samples, write_json\n",
    "from code_base.utils.metrics import score_numpy\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbefe7e-9217-4b0e-8d8d-7b690038a69f",
   "metadata": {},
   "source": [
    "# Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606cef9-2299-44af-bf31-c0efe46ad739",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lt ../logdirs/ | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8b749-45d8-4985-9649-96c42d7514c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bird2id_source = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024_PrevComp.json\")\n",
    "# bird2id_target = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024.json\")\n",
    "\n",
    "# id2bird_source = {v:k for k,v in bird2id_source.items()}\n",
    "# id2bird_target = {v:k for k,v in bird2id_target.items()}\n",
    "\n",
    "# REARRANGE_INDICES = np.array([\n",
    "#     bird2id_source[id2bird_target[i]] for i in range(len(id2bird_target))\n",
    "# ]).astype(int)\n",
    "\n",
    "# STRICT_LOAD = False\n",
    "\n",
    "# def prune_checkpoint_rule(inp_chkp):\n",
    "#     inp_chkp[\"head.attention.weight\"] = inp_chkp[\"head.attention.weight\"][REARRANGE_INDICES]\n",
    "#     inp_chkp[\"head.attention.bias\"] = inp_chkp[\"head.attention.bias\"][REARRANGE_INDICES]\n",
    "    \n",
    "#     inp_chkp[\"head.fix_scale.weight\"] = inp_chkp[\"head.fix_scale.weight\"][REARRANGE_INDICES]\n",
    "#     inp_chkp[\"head.fix_scale.bias\"] = inp_chkp[\"head.fix_scale.bias\"][REARRANGE_INDICES]\n",
    "\n",
    "#     return inp_chkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6790a-22de-4508-a24b-8b5cad6deb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bird2id_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293b406-e4dd-41db-82a4-6c40cc78f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASS = WaveCNNAttenClasifier\n",
    "TRAIN_PERIOD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663cbb4-ee61-456a-bbaa-ae7781f4d4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"tf_efficientnetv2_s_in21k_Exp_noamp_64bs_5sec_BasicAug_EqualBalancing_AdamW1e4_CosBatchLR1e6_Epoch50_FocalBCELoss_LSF1005_FromPrebs1_PseudoF2PT05MT01P04I2_OOFPI2M2\"\n",
    "\n",
    "conf_path = glob(f\"../logdirs/{EXP_NAME}/code/*train_configs*.py\")\n",
    "assert len(conf_path) == 1\n",
    "conf_path = conf_path[0]\n",
    "!cat {conf_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46147957-77dc-44bf-928e-0fd92762a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    {\n",
    "        \"model_config\": dict(\n",
    "            backbone=\"tf_efficientnetv2_s_in21k\",\n",
    "            mel_spec_paramms={\n",
    "                \"sample_rate\": 32000,\n",
    "                \"n_mels\": 128,\n",
    "                \"f_min\": 20,\n",
    "                \"n_fft\": 2048,\n",
    "                \"hop_length\": 512,\n",
    "                \"normalized\": True,\n",
    "            },\n",
    "            head_config={\n",
    "                \"p\": 0.5,\n",
    "                \"num_class\": 206,\n",
    "                \"train_period\": TRAIN_PERIOD,\n",
    "                \"infer_period\": TRAIN_PERIOD,\n",
    "                \"output_type\": \"clipwise_pred_long\",\n",
    "            },\n",
    "            exportable=True,\n",
    "            fixed_amplitude_to_db=True\n",
    "        ),\n",
    "        \"exp_name\": \"tf_efficientnetv2_s_in21k_Exp_noamp_64bs_5sec_BasicAug_EqualBalancing_AdamW1e4_CosBatchLR1e6_Epoch50_FocalBCELoss_LSF1005_FromXCV2ExtSWA_PseudoF2PT05MT01P04I2MOOFRev_AddRareBirdsNoLeak\",\n",
    "        \"fold\": [0, 1, 2, 3, 4],\n",
    "        # \"fold\": [1, 3, 4],\n",
    "        \"chkp_name\":\"last.ckpt\",\n",
    "        \"swa_checkpoint_regex\": r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "        \"swa_sort_rule\": lambda x: -float(x[\"valid_roc_auc\"]),\n",
    "        \"delete_prefix\": \"model.\",\n",
    "        \"n_swa_models\": 1,\n",
    "        \"model_output_key\": None,\n",
    "        # \"prune_checkpoint_func\": prune_checkpoint_rule\n",
    "    },\n",
    "    {\n",
    "        \"model_config\": dict(\n",
    "            backbone=\"tf_efficientnetv2_s_in21k\",\n",
    "            mel_spec_paramms={\n",
    "                \"sample_rate\": 32000,\n",
    "                \"n_mels\": 128,\n",
    "                \"f_min\": 20,\n",
    "                \"n_fft\": 2048,\n",
    "                \"hop_length\": 512,\n",
    "                \"normalized\": True,\n",
    "            },\n",
    "            head_config={\n",
    "                \"p\": 0.5,\n",
    "                \"num_class\": 206,\n",
    "                \"train_period\": TRAIN_PERIOD,\n",
    "                \"infer_period\": TRAIN_PERIOD,\n",
    "                \"output_type\": \"clipwise_pred_long\",\n",
    "            },\n",
    "            exportable=True,\n",
    "            fixed_amplitude_to_db=True\n",
    "        ),\n",
    "        \"exp_name\": \"tf_efficientnetv2_s_in21k_Exp_noamp_64bs_5sec_BasicAug_EqualBalancing_AdamW1e4_CosBatchLR1e6_Epoch50_FocalBCELoss_LSF1005_FromPrebs1_PseudoF2PT05MT01P04I2_OOFPI2M2\",\n",
    "        \"fold\": [0, 1, 2, 3, 4],\n",
    "        \"chkp_name\":\"last.ckpt\",\n",
    "        \"swa_checkpoint_regex\": r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "        \"swa_sort_rule\": lambda x: -float(x[\"valid_roc_auc\"]),\n",
    "        \"delete_prefix\": \"model.\",\n",
    "        \"n_swa_models\": 1,\n",
    "        \"model_output_key\": None,\n",
    "        # \"prune_checkpoint_func\": prune_checkpoint_rule\n",
    "    },\n",
    "    \n",
    "    # {\n",
    "    #     \"model_config\": dict(\n",
    "    #         backbone=\"eca_nfnet_l0\",\n",
    "    #         mel_spec_paramms={\n",
    "    #             \"sample_rate\": 32000,\n",
    "    #             \"n_mels\": 128,\n",
    "    #             \"f_min\": 20,\n",
    "    #             \"n_fft\": 2048,\n",
    "    #             \"hop_length\": 512,\n",
    "    #             \"normalized\": True,\n",
    "    #         },\n",
    "    #         head_config={\n",
    "    #             \"p\": 0.5,\n",
    "    #             \"num_class\": 206,\n",
    "    #             \"train_period\": TRAIN_PERIOD,\n",
    "    #             \"infer_period\": TRAIN_PERIOD,\n",
    "    #             \"output_type\": \"clipwise_pred_long\",\n",
    "    #         },\n",
    "    #         exportable=True,\n",
    "    #         fixed_amplitude_to_db=True\n",
    "    #     ),\n",
    "    #     \"exp_name\": \"eca_nfnet_l0_Exp_noamp_64bs_5sec_BasicAug_SqrtBalancing_Radamlr1e3_CosBatchLR1e6_Epoch50_FocalBCELoss_LSF1005_FromXCV2Best_PseudoF2PT05MT01P04I3_MinorOverSampleV1\",\n",
    "    #     \"fold\": [0, 1, 2, 3, 4],\n",
    "    #     \"chkp_name\":\"last.ckpt\",\n",
    "    #     \"swa_checkpoint_regex\": r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "    #     \"swa_sort_rule\": lambda x: -float(x[\"valid_roc_auc\"]),\n",
    "    #     \"delete_prefix\": \"model.\",\n",
    "    #     \"n_swa_models\": 1,\n",
    "    #     \"model_output_key\": None,\n",
    "    #     # \"prune_checkpoint_func\": prune_checkpoint_rule\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cba2c8-e51d-49f0-8045-5c1ed7739b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_upload_chkp(\n",
    "    model_class,\n",
    "    model_config,\n",
    "    model_device,\n",
    "    model_chkp_root,\n",
    "    model_chkp_basename=None,\n",
    "    model_chkp_regex=None,\n",
    "    delete_prefix=None,\n",
    "    swa_sort_rule=None,\n",
    "    n_swa_to_take=3,\n",
    "    prune_checkpoint_func=None\n",
    "):\n",
    "    if model_chkp_basename is None:\n",
    "        basenames = os.listdir(model_chkp_root)\n",
    "        checkpoints = []\n",
    "        for el in basenames:\n",
    "            matches = re.findall(model_chkp_regex, el)\n",
    "            if not matches:\n",
    "                continue\n",
    "            parsed_dict = {key: value for key, value in matches}\n",
    "            parsed_dict[\"name\"] = el\n",
    "            checkpoints.append(parsed_dict)\n",
    "        print(\"SWA checkpoints\")\n",
    "        pprint(checkpoints)\n",
    "        checkpoints = sorted(checkpoints, key=swa_sort_rule)\n",
    "        checkpoints = checkpoints[:n_swa_to_take]\n",
    "        print(\"SWA sorted checkpoints\")\n",
    "        pprint(checkpoints)\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints = [\n",
    "                torch.load(os.path.join(model_chkp_root, el[\"name\"]), map_location=\"cpu\")[\"state_dict\"] for el in checkpoints\n",
    "            ]\n",
    "            t_chkp = avarage_weights(\n",
    "                nn_weights=checkpoints,\n",
    "                delete_prefix=delete_prefix\n",
    "            )\n",
    "        else:\n",
    "            chkp_path = os.path.join(model_chkp_root, checkpoints[0][\"name\"])\n",
    "            print(\"vanilla model\")\n",
    "            print(\"Loading\", chkp_path)\n",
    "            t_chkp = torch.load(\n",
    "                chkp_path, \n",
    "                map_location=\"cpu\"\n",
    "            )[\"state_dict\"]\n",
    "            if delete_prefix is not None:\n",
    "                t_chkp = delete_prefix_from_chkp(t_chkp, delete_prefix)\n",
    "    else:\n",
    "        chkp_path = os.path.join(model_chkp_root, model_chkp_basename)\n",
    "        print(\"vanilla model\")\n",
    "        print(\"Loading\", chkp_path)\n",
    "        t_chkp = torch.load(\n",
    "            chkp_path, \n",
    "            map_location=\"cpu\"\n",
    "        )[\"state_dict\"]\n",
    "        if delete_prefix is not None:\n",
    "            t_chkp = delete_prefix_from_chkp(t_chkp, delete_prefix)\n",
    "\n",
    "    if prune_checkpoint_func is not None:\n",
    "        t_chkp = prune_checkpoint_func(t_chkp)\n",
    "    t_model = model_class(**model_config, device=model_device) \n",
    "    print(\"Missing keys: \", set(t_model.state_dict().keys()) - set(t_chkp))\n",
    "    print(\"Extra keys: \",  set(t_chkp) - set(t_model.state_dict().keys()))\n",
    "    t_model.load_state_dict(t_chkp, strict=False)\n",
    "    t_model.eval()\n",
    "    return t_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9f892-edcd-4bbe-90bc-2f17d920d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "for config in MODELS:\n",
    "    model.extend([create_model_and_upload_chkp(\n",
    "        model_class=MODEL_CLASS,\n",
    "        model_config=config['model_config'],\n",
    "        model_device=\"cpu\",\n",
    "        model_chkp_root=f\"../logdirs/{config['exp_name']}/fold_{m_i}/checkpoints\",\n",
    "        model_chkp_basename=config[\"chkp_name\"] if config[\"swa_checkpoint_regex\"] is None else None,\n",
    "        model_chkp_regex=config.get(\"swa_checkpoint_regex\"),\n",
    "        swa_sort_rule=config.get(\"swa_sort_rule\"),\n",
    "        n_swa_to_take=config.get(\"n_swa_models\", 3),\n",
    "        delete_prefix=config.get(\"delete_prefix\"),\n",
    "        prune_checkpoint_func=config.get(\"prune_checkpoint_func\")\n",
    "    ) for m_i in config[\"fold\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48bec63-c3f5-4f53-a9f3-aeb132df2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142313a-73cf-4df7-843e-e98ad0e137d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exportable_ensem = ONNXEnsemble(\n",
    "    model_class=MODEL_CLASS,\n",
    "    configs=list(chain(*[\n",
    "        [deepcopy(config['model_config']) for _ in config[\"fold\"]] for config in MODELS\n",
    "    ])),\n",
    "    extract_spec_ones=True\n",
    "    # avarage_type=\"identity\"\n",
    "    # weights=[2.0] * 5 + [1.0] * 5\n",
    ")\n",
    "assert len(exportable_ensem.models) == len(model)\n",
    "for model_id in range(len(model)):\n",
    "    exportable_ensem.models[model_id].load_state_dict(model[model_id].state_dict())\n",
    "    exportable_ensem.models[model_id].eval()\n",
    "exportable_ensem.eval()\n",
    "convert_to_onnx(\n",
    "    model_to_convert=exportable_ensem,\n",
    "    sample_input=torch.randn(5, TRAIN_PERIOD * 32_000),\n",
    "    base_path=f\"../logdirs/ebs_19__ebs_13/onnx_ensem_5first_folds\",\n",
    "    use_fp16=True,\n",
    "    use_openvino=True,\n",
    "    opset_version=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec5a73-ded8-4532-99f8-b5727b670842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../logdirs/convnext_small_fb_in22k_ft_in1k_384__convnextv2_tiny_fcmae_ft_in22k_in1k_384__eca_nfnet_l0_noval_v27_075Clipwise025TimeMax_GausMean -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ea4bb-1236-4a9e-b8a2-6511c778bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../logdirs/convnext_small_fb_in22k_ft_in1k_384__convnextv2_tiny_fcmae_ft_in22k_in1k_384__eca_nfnet_l0_noval_v27_075Clipwise025TimeMax_GausMean -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b4ee8-ca40-4187-ad58-be7b6c4aee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lt ../logdirs/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e191dc-daa5-4aad-900c-99cb92470f40",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899cb74-eaff-4440-9825-d9c17ef714c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f\"../logdirs/{EXP_NAME}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f184826-0a01-43e1-a117-ce1223640bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "model = core.read_model(model=f\"../logdirs/{EXP_NAME}/onnx_ensem_openvino_fp16/model_simpl.xml\")\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b420c5b-10d3-416c-b8f1-372ae68fe070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randn(5, 32000*5).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4cbcb-0d72-440f-90a1-0786699bee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786d693-bc5c-46ca-ab13-61911edcf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = compiled_model([sample])[compiled_model.output(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff9e36-2c14-41df-832b-7d7c81dde53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db8867-3087-4dfd-9cbd-c7057bf55e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd7ea3-c0d3-4a51-b2e5-9326d266a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22496b86-f090-4527-8f8b-55a1088b9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = ort.InferenceSession(\n",
    "    f\"../logdirs/{EXP_NAME}/onnx_ensem_fp16/model_simpl.onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dede71-c5f1-4f10-858e-ac2dd87f7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = torch.from_numpy(np.random.randn(32000*5)).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a4073-e6ef-448b-8d6e-4a146dc0abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70a3d5-63d7-4304-b45d-5de7cb83befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out = onnx_model.run(\n",
    "    None,\n",
    "    {\"input\": sample}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d5cb8-3ed3-4024-afe8-c9b9a4db2105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ca089-7c06-4e31-adb5-1ca848d46485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85236d5f-49cb-4154-86a8-712c3074b9e1",
   "metadata": {},
   "source": [
    "# Emulate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d7599-2751-4c9f-b01b-742fdf3eab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config_test = {\n",
    "   # \"root\": \"../data/train_audio\",\n",
    "    \"root\": \"\",\n",
    "   \"label_str2int_mapping_path\": \"../data/bird2int_2025.json\",\n",
    "   \"n_cores\": 64,\n",
    "   \"use_audio_cache\": True,\n",
    "   \"test_mode\": True,\n",
    "   \"segment_len\": 5,\n",
    "    \"do_not_exceed_duration\": True,\n",
    "   \"lookback\": None,\n",
    "   \"lookahead\": None,\n",
    "    \"step\": 2.5,\n",
    "    \"sample_id\": None,\n",
    "    \"late_normalize\": True,\n",
    "    \"load_normalize\": False,\n",
    "    # \"step\": None,\n",
    "    \"validate_sr\": 32_000\n",
    "}\n",
    "loader_config = {\n",
    "    \"batch_size\": 24,\n",
    "    \"drop_last\": False,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfbe69-331b-40c9-8134-f919088bc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_au_pathes = glob(\"../data/train_audio_soundscapes/*.ogg\")\n",
    "test_au_pathes = test_au_pathes[:10]\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"filename\": test_au_pathes,\n",
    "    \"duration_s\": [librosa.get_duration(filename=el) for el in test_au_pathes]\n",
    "})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c23e92-cb41-4472-8179-c5c08fa4b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(\n",
    "#     \"../data/train_and_prev_comps_extendedv1_pruneSL_XConly2025_snipet11052025_hdf5_csa_fixedaudiometa_h5pyDur.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dbece-c1a5-42e4-8d6e-7625d2035d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df.iloc[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884048a6-5c1f-4ff5-bc79-e1e94a2cfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = WaveAllFileDataset(df=test_df, **ds_config_test)\n",
    "loader_test = torch.utils.data.DataLoader(\n",
    "    ds_test,\n",
    "    **loader_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ec2cc-502e-47de-8f7e-65455f9565d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_test) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ded9ce-06a4-4662-841d-c28d8dfc305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "60 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638afff-c6ef-4543-97a6-04a54d4a7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbeab53-ada0-4071-aba6-4fcefb8fc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "1760000 / 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6ce2c-bb57-43f4-a790-ad1f87e11872",
   "metadata": {},
   "outputs": [],
   "source": [
    "1840000 / 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57217660-c5fc-4450-872d-c146487b9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test.sampleidx_2_dfidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a6e31-3b01-4051-aab9-a68302922660",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ds_test[i][-1] for i in range(len(ds_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7307a-c6b7-42e9-871c-4cb3b6a319a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model_path_):\n",
    "    core = ov.Core()\n",
    "    compiled_model_ = core.read_model(model=model_path_)\n",
    "    return core.compile_model(model=compiled_model_, device_name=\"CPU\")\n",
    "\n",
    "inference_class_onnx = BirdsInference(\n",
    "    device=\"cpu\",\n",
    "    verbose_tqdm=True,\n",
    "    use_sigmoid=False,\n",
    "    use_compiled_fp16=False,\n",
    ")\n",
    "onnx_model = compile_model(\n",
    "    \"../logdirs/best_ensem_16052025/onnx_ensem_5first_folds_openvino_fp16/model_simpl.xml\"\n",
    ")\n",
    "test_preds, test_dfidx, test_end = inference_class_onnx.predict_test_loader(\n",
    "    nn_models=onnx_model,\n",
    "    data_loader=loader_test,\n",
    "    is_openvino_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b4cd95-f605-4f52-b3f9-c7a7500a4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_predictions(test_preds_, test_dfidx_, test_end_):\n",
    "    unique_files = np.unique(test_dfidx_)\n",
    "    agg_preds = []\n",
    "    agg_dfidx = []\n",
    "    agg_end = []\n",
    "\n",
    "    for file_id in unique_files:\n",
    "        mask = test_dfidx_ == file_id\n",
    "        preds = test_preds_[mask]\n",
    "        ends = test_end_[mask]\n",
    "\n",
    "        if len(preds) < 1:\n",
    "            continue\n",
    "\n",
    "        num_preds = len(preds)\n",
    "        file_agg_preds = []\n",
    "        file_agg_ends = []\n",
    "\n",
    "        for i in range(num_preds):\n",
    "            components = []\n",
    "            weights = []\n",
    "\n",
    "            # t-1\n",
    "            if i > 0:\n",
    "                components.append(preds[i - 1])\n",
    "                weights.append(0.25)\n",
    "            # zero-padding is removed; only normalize used weights\n",
    "            # t\n",
    "            components.append(preds[i])\n",
    "            weights.append(0.5)\n",
    "            # t+1\n",
    "            if i < num_preds - 1:\n",
    "                components.append(preds[i + 1])\n",
    "                weights.append(0.25)\n",
    "\n",
    "            weights = np.array(weights)\n",
    "            components = np.stack(components, axis=0)\n",
    "            normalized_weights = weights / weights.sum()\n",
    "            weighted_pred = (normalized_weights[:, None] * components).sum(axis=0)\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                file_agg_preds.append(weighted_pred)\n",
    "                file_agg_ends.append(ends[i])\n",
    "\n",
    "        agg_preds.append(np.stack(file_agg_preds, axis=0))\n",
    "        agg_dfidx.append(np.full(len(file_agg_preds), file_id))\n",
    "        agg_end.append(np.array(file_agg_ends))\n",
    "\n",
    "    return (\n",
    "        np.concatenate(agg_preds, axis=0),\n",
    "        np.concatenate(agg_dfidx, axis=0),\n",
    "        np.concatenate(agg_end, axis=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33900e3e-f264-411c-9408-23344aa93469",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_aggr, test_dfidx_aggr, test_end_aggr = aggregate_predictions(\n",
    "    test_preds_=test_preds,\n",
    "    test_dfidx_=test_dfidx,\n",
    "    test_end_=test_end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e1edf-36a2-438b-8721-c48278777a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end_aggr.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f757d-1189-476a-b1c8-d5ab3cdd6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(\n",
    "    test_preds[23] * (0.5 / 0.75)  + test_preds[24] * (0.25 / 0.75),\n",
    "    test_preds_aggr[12]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e3003-c392-4113-a320-586ae0442323",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(\n",
    "    test_preds[26] * 0.25  + test_preds[27] * 0.5 + test_preds[28] * 0.25,\n",
    "    test_preds_aggr[14]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e64fe9-c0bb-4752-bb97-918f8ac4f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(\n",
    "    test_preds[228] * (0.25 / 0.75)  + test_preds[229] * (0.5 / 0.75),\n",
    "    test_preds_aggr[119]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3cff26-bbcc-4441-8a69-f5aa7bc8c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(test_dfidx == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afb484-5f67-4b5c-996e-2c86a93cde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end[np.where(test_dfidx == 9)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae57f6-baeb-4ba5-bb6b-5e38a53fdb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(test_dfidx_aggr == 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9421de-351d-4f97-b7e8-66c787b09af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_end_aggr[np.where(test_dfidx_aggr == 9)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6969403-60ea-4217-8788-197547b143d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing_array(only_probs, top=6):\n",
    "    print(\"Top\", top)\n",
    "    N, F = only_probs.shape\n",
    "    only_probs = only_probs.reshape((N//12, 12, F))\n",
    "    # mean_ = np.mean(np.sort(only_probs, axis=1)[:, 8:], axis=1, keepdims=True)\n",
    "    mean_ = np.mean(np.sort(only_probs, axis=1)[:, -top:], axis=1, keepdims=True)\n",
    "    only_probs *= mean_\n",
    "    return only_probs.reshape((N, F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d111787-ae03-454c-bffb-e88cdc147435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mi in range(test_preds.shape[-1]):\n",
    "    test_preds[:,:,mi] = postprocessing_array(test_preds[:,:,mi], top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f4eaf-535b-4a5b-8c89-ca685aeed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[:,:,0].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10f007-1e3f-4e5e-97af-5ba0f9860ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f69d0-9beb-46c2-a44d-aa3898e040ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis(rankdata, axis=0, arr=test_preds).mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a23067-52ed-43ea-8ac1-e38f6df29b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx = compose_submission_dataframe(\n",
    "    probs=test_preds_onnx,\n",
    "    dfidxs=test_dfidx_onnx,\n",
    "    end_seconds=test_end_onnx,\n",
    "    filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "    bird2id=bird2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a935d6-b76a-4a0a-9b7b-c4216cbe0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx = compose_submission_dataframe(\n",
    "    probs=test_preds_aggr,\n",
    "    dfidxs=test_dfidx_aggr,\n",
    "    end_seconds=test_end_aggr,\n",
    "    filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "    bird2id=bird2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa00ef6-811a-433b-b29b-b78cab0138d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

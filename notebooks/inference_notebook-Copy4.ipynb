{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b5865-b35e-4a2d-bf9f-e5f3ccb7ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b6336-a425-4dac-b1d7-2d4164c39e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import h5py\n",
    "import onnxruntime as ort\n",
    "import openvino as ov\n",
    "import torch.quantization.quantize_fx as quantize_fx\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "from os.path import join as pjoin\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "# from code_base.utils import parallel_librosa_load, groupby_np_array, stack_and_max_by_samples, macro_f1_similarity, N_CLASSES_2021_2022, N_CLASSES_2021, comp_metric, N_CLASSES_XC_LIGIT_SHORTEN, N_CLASSES_XC_LIGIT_EVEN_SHORTEN\n",
    "# from code_base.utils.constants import SAMPLE_RATE\n",
    "from code_base.utils.onnx_utils import ONNXEnsemble, convert_to_onnx\n",
    "from code_base.models import WaveCNNClasifier, WaveCNNAttenClasifier, WaveTDNNClasifier\n",
    "from code_base.datasets import WaveDataset, WaveAllFileDataset\n",
    "from code_base.utils.swa import avarage_weights, delete_prefix_from_chkp\n",
    "from code_base.inefernce import BirdsInference\n",
    "from code_base.utils import load_json, compose_submission_dataframe, groupby_np_array, stack_and_max_by_samples, write_json\n",
    "from code_base.utils.metrics import score_numpy\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981361da-b8d9-4162-820d-2a4b624850a4",
   "metadata": {},
   "source": [
    "# Clean logdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d48232-1c77-4018-9f67-234697d62c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filt_criteria(input):\n",
    "#     num_folds = sum(\"fold_\" in el for el in glob(pjoin(input, \"*\")))\n",
    "#     if num_folds > 0 and num_folds < 5:\n",
    "#         print(input, num_folds)\n",
    "#         return False\n",
    "#     else:\n",
    "#         return True\n",
    "    \n",
    "# all_logdirs = glob(\"../logdirs/*\")\n",
    "# logdirs_to_remove = [el for el in all_logdirs if not filt_criteria(el)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174fa79-a461-4706-8fc1-7e67d9945ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for el in logdirs_to_remove[:-1]:\n",
    "#     !rm {el} -rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737b54a-20f3-40b4-893c-018539b384b3",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc129540-3ade-4b64-88f7-1dd662d3c038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -lt ../logdirs/convnextv2_tiny_fcmae_ft_in22k_in1k_384_Exp_noamp_64bs_5sec_PrevCompXCScoredDataNoSecLab_BackGroundSoundScapeP05_mixupP05_RandomFiltering_balancedSampler_Radamlr1e4_CosBatchLR1e6_Epoch30_BCELoss_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893be61-a93d-41f7-8a73-8b447d1f769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Possible exps:\\n\\n{}\".format(\"\\n\".join(os.listdir(\"../logdirs/\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72915839-edd3-43d2-a51d-bbc70fd3e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird2id_source = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024_scoed_add_data.json\")\n",
    "bird2id_target = load_json(\"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024.json\")\n",
    "\n",
    "id2bird_source = {v:k for k,v in bird2id_source.items()}\n",
    "id2bird_target = {v:k for k,v in bird2id_target.items()}\n",
    "\n",
    "REARRANGE_INDICES = np.array([\n",
    "    bird2id_source[id2bird_target[i]] for i in range(len(id2bird_target))\n",
    "]).astype(int)\n",
    "\n",
    "def prune_checkpoint_rule(inp_chkp):\n",
    "    inp_chkp[\"head.attention.weight\"] = inp_chkp[\"head.attention.weight\"][REARRANGE_INDICES]\n",
    "    inp_chkp[\"head.attention.bias\"] = inp_chkp[\"head.attention.bias\"][REARRANGE_INDICES]\n",
    "    \n",
    "    inp_chkp[\"head.fix_scale.weight\"] = inp_chkp[\"head.fix_scale.weight\"][REARRANGE_INDICES]\n",
    "    inp_chkp[\"head.fix_scale.bias\"] = inp_chkp[\"head.fix_scale.bias\"][REARRANGE_INDICES]\n",
    "\n",
    "    return inp_chkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3c413-f9e7-4998-8654-1be7aab82c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"tf_efficientnetv2_b1_in1k_Exp_noamp_FixedAmp2Db_64bs_5sec_TimeFlip05_FormixupAlpha05NormedBinTgtEqW_Radamlr1e3_CosBatchLR1e6_Epoch30_SpecAugV207_FocalBCELoss_5Folds_NoDuplsV1\"\n",
    "TRAIN_PERIOD = 5\n",
    "print(\"Possible checkpoints:\\n\\n{}\".format(\"\\n\".join(set([os.path.basename(el) for el in glob(f\"../logdirs/{EXP_NAME}/*/checkpoints/*.ckpt*\") if \"train\" not in os.path.basename(el)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b30cda-80f1-4f4d-bd30-ded79880f16f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_path = glob(f\"../logdirs/{EXP_NAME}/code/*train_configs*.py\")\n",
    "assert len(conf_path) == 1\n",
    "conf_path = conf_path[0]\n",
    "!cat {conf_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81f417-8370-4a68-85e7-89b47ab1e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Main\n",
    "    \"run_validation\": True,\n",
    "    \"run_test\": False,\n",
    "    # Inference Class\n",
    "    \"use_sigmoid\": False,\n",
    "    \"use_compiled_fp16\": False,\n",
    "    \"aggregate_preds\": True,\n",
    "    # Data config\n",
    "    \"train_df_path\": \"/home/vova/data/exps/birdclef_2024/birdclef_2024/train_metadata_extended_noduplv1.csv\",\n",
    "    \"split_path\": \"/home/vova/data/exps/birdclef_2024/cv_splits/birdclef_2024_5_folds_split_nodupl.npy\",\n",
    "    \"n_folds\":5,\n",
    "    # \"n_folds\": 1,\n",
    "    \"train_data_root\":\"/home/vova/data/exps/birdclef_2024/birdclef_2024/train_audio/\",\n",
    "    \"test_data_root\":\"/home/vova/data/exps/birdclef_2024/birdclef_2024/unlabeled_soundscapes/*.ogg\",\n",
    "    \"label_map_data_path\": \"/home/vova/data/exps/birdclef_2024/class_mappings/bird2int_2024.json\",\n",
    "    \"scored_birds_path\":\"/home/vova/data/exps/birdclef_2024/scored_birds/sb_2024.json\", \n",
    "    \"lookback\":None,\n",
    "    \"lookahead\":None,\n",
    "    \"segment_len\":5,\n",
    "    \"step\": None,\n",
    "    \"late_normalize\": True,\n",
    "    # Model config\n",
    "    \"exp_name\":EXP_NAME,\n",
    "    \"model_class\": WaveCNNAttenClasifier,\n",
    "    \"model_config\": dict(\n",
    "        backbone=\"tf_efficientnetv2_b1.in1k\",\n",
    "        mel_spec_paramms={\n",
    "            \"sample_rate\": 32000,\n",
    "            \"n_mels\": 128,\n",
    "            \"f_min\": 20,\n",
    "            \"n_fft\": 2048,\n",
    "            \"hop_length\": 512,\n",
    "            \"normalized\": True,\n",
    "        },\n",
    "        head_config={\n",
    "            \"p\": 0.5,\n",
    "            \"num_class\": 188,\n",
    "            \"train_period\": TRAIN_PERIOD,\n",
    "            \"infer_period\": TRAIN_PERIOD,\n",
    "            \"output_type\": \"clipwise_pred_long\",\n",
    "        },\n",
    "        exportable=True,\n",
    "        fixed_amplitude_to_db=True\n",
    "    ),\n",
    "    \"chkp_name\":\"last.ckpt\",\n",
    "    \"swa_checkpoint_regex\": r'(?P<key>\\w+)=(?P<value>[\\d.]+)(?=\\.ckpt|$)',\n",
    "    \"use_sigmoid\": True,\n",
    "    \"swa_sort_rule\": lambda x: -float(x[\"valid_roc_auc\"]),\n",
    "    \"delete_prefix\": \"model.\",\n",
    "    \"n_swa_models\": 3,\n",
    "    \"model_output_key\": None,\n",
    "    # \"prune_checkpoint_func\": prune_checkpoint_rule,\n",
    "\n",
    "    # Compilation config\n",
    "    \"use_openvino\": True,\n",
    "    \"use_fp16\": True,\n",
    "    \"folds_to_onnx\": [0, 1, 2, 3, 4],\n",
    "    \"final_activation\": \"softmax\"\n",
    "}\n",
    "\n",
    "if CONFIG.get(\"use_sed_mode\", False):\n",
    "    assert CONFIG[\"step\"] is not None\n",
    "else:\n",
    "    assert CONFIG[\"step\"] is None\n",
    "    \n",
    "if \"folds\" not in CONFIG:\n",
    "    CONFIG[\"folds\"] = list(range(CONFIG[\"n_folds\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51829533-f273-4a67-9260-cd764da76f6d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff85dcc-47fd-4bed-beb3-fa4effb9236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird2id = load_json(CONFIG[\"label_map_data_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a5c62-d255-4175-9da5-3787e8960a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    df = pd.read_csv(CONFIG[\"train_df_path\"])\n",
    "    split = np.load(CONFIG[\"split_path\"], allow_pickle=True)\n",
    "    val_df = [df.iloc[split[i][1]].reset_index(drop=True) for i in CONFIG[\"folds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62a903-a970-44a7-a61e-cefdf94f8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    test_au_pathes = glob(CONFIG[\"test_data_root\"])[:20]\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        \"filename\": test_au_pathes,\n",
    "        \"duration_s\": [librosa.get_duration(filename=el) for el in test_au_pathes]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be608001-f361-4fab-a7af-d69c224a38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    val_ds_conig = {\n",
    "       \"root\": CONFIG[\"train_data_root\"],\n",
    "       \"label_str2int_mapping_path\": CONFIG[\"label_map_data_path\"],\n",
    "       \"use_audio_cache\": True,\n",
    "       \"n_cores\": 64,\n",
    "       \"verbose\": False,\n",
    "       \"segment_len\": CONFIG[\"segment_len\"],\n",
    "       \"lookback\":CONFIG[\"lookback\"],\n",
    "       \"lookahead\":CONFIG[\"lookahead\"],\n",
    "       \"sample_id\": None,\n",
    "       \"late_normalize\": CONFIG[\"late_normalize\"],\n",
    "       \"step\": CONFIG[\"step\"],\n",
    "        \"validate_sr\": 32_000\n",
    "    }\n",
    "if CONFIG[\"run_test\"]:\n",
    "    ds_config_test = {\n",
    "       \"root\": \"\",\n",
    "       \"label_str2int_mapping_path\": CONFIG[\"label_map_data_path\"],\n",
    "       \"n_cores\": 64,\n",
    "       \"use_audio_cache\": True,\n",
    "       \"test_mode\": True,\n",
    "       \"segment_len\": CONFIG[\"segment_len\"],\n",
    "       \"lookback\":CONFIG[\"lookback\"],\n",
    "       \"lookahead\":CONFIG[\"lookahead\"],\n",
    "        \"sample_id\": None,\n",
    "        \"late_normalize\": CONFIG[\"late_normalize\"],\n",
    "        \"step\": CONFIG[\"step\"],\n",
    "        \"validate_sr\": 32_000\n",
    "    }\n",
    "loader_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"drop_last\": False,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014d6e6-56e9-45d6-9dcf-c76c4f59bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    ds_test = WaveAllFileDataset(df=test_df, **ds_config_test)\n",
    "if CONFIG[\"run_validation\"]:\n",
    "    ds_val = [WaveAllFileDataset(df=df, **val_ds_conig) for df in val_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01310c22-1f3d-45a0-a8c8-1dae95b0c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    loader_val = [torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        **loader_config,\n",
    "    )for ds in ds_val]\n",
    "if CONFIG[\"run_test\"]:\n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        ds_test,\n",
    "        **loader_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc85eee-c91b-408f-b1e6-a6ea47dacfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf70ba-989d-4c39-b97b-473e2b69c72f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4d685-a722-402c-951a-7b1ae0bd1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_upload_chkp(\n",
    "    model_class,\n",
    "    model_config,\n",
    "    model_device,\n",
    "    model_chkp_root,\n",
    "    model_chkp_basename=None,\n",
    "    model_chkp_regex=None,\n",
    "    delete_prefix=None,\n",
    "    swa_sort_rule=None,\n",
    "    n_swa_to_take=3,\n",
    "    prune_checkpoint_func=None\n",
    "):\n",
    "    if model_chkp_basename is None:\n",
    "        basenames = os.listdir(model_chkp_root)\n",
    "        checkpoints = []\n",
    "        for el in basenames:\n",
    "            matches = re.findall(model_chkp_regex, el)\n",
    "            if not matches:\n",
    "                continue\n",
    "            parsed_dict = {key: value for key, value in matches}\n",
    "            parsed_dict[\"name\"] = el\n",
    "            checkpoints.append(parsed_dict)\n",
    "        print(\"SWA checkpoints\")\n",
    "        pprint(checkpoints)\n",
    "        checkpoints = sorted(checkpoints, key=swa_sort_rule)\n",
    "        checkpoints = checkpoints[:n_swa_to_take]\n",
    "        print(\"SWA sorted checkpoints\")\n",
    "        pprint(checkpoints)\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints = [\n",
    "                torch.load(os.path.join(model_chkp_root, el[\"name\"]), map_location=\"cpu\")[\"state_dict\"] for el in checkpoints\n",
    "            ]\n",
    "            t_chkp = avarage_weights(\n",
    "                nn_weights=checkpoints,\n",
    "                delete_prefix=delete_prefix\n",
    "            )\n",
    "        else:\n",
    "            chkp_path = os.path.join(model_chkp_root, checkpoints[0][\"name\"])\n",
    "            print(\"vanilla model\")\n",
    "            print(\"Loading\", chkp_path)\n",
    "            t_chkp = torch.load(\n",
    "                chkp_path, \n",
    "                map_location=\"cpu\"\n",
    "            )[\"state_dict\"]\n",
    "            if delete_prefix is not None:\n",
    "                t_chkp = delete_prefix_from_chkp(t_chkp, delete_prefix)\n",
    "    else:\n",
    "        chkp_path = os.path.join(model_chkp_root, model_chkp_basename)\n",
    "        print(\"vanilla model\")\n",
    "        print(\"Loading\", chkp_path)\n",
    "        t_chkp = torch.load(\n",
    "            chkp_path, \n",
    "            map_location=\"cpu\"\n",
    "        )[\"state_dict\"]\n",
    "        if delete_prefix is not None:\n",
    "            t_chkp = delete_prefix_from_chkp(t_chkp, delete_prefix)\n",
    "\n",
    "    if prune_checkpoint_func is not None:\n",
    "        t_chkp = prune_checkpoint_func(t_chkp)\n",
    "    t_model = model_class(**model_config, device=model_device) \n",
    "    print(\"Missing keys: \", set(t_model.state_dict().keys()) - set(t_chkp))\n",
    "    print(\"Extra keys: \",  set(t_chkp) - set(t_model.state_dict().keys()))\n",
    "    t_model.load_state_dict(t_chkp, strict=False)\n",
    "    t_model.eval()\n",
    "    return t_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f52a95-e947-475d-8401-428a42763f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = [create_model_and_upload_chkp(\n",
    "    model_class=CONFIG[\"model_class\"],\n",
    "    model_config=CONFIG['model_config'],\n",
    "    model_device=\"cuda\",\n",
    "    model_chkp_root=f\"../logdirs/{CONFIG['exp_name']}/fold_{m_i}/checkpoints\",\n",
    "    # model_chkp_root=f\"../logdirs/{CONFIG['exp_name']}/checkpoints\",\n",
    "    model_chkp_basename=CONFIG[\"chkp_name\"] if CONFIG[\"swa_checkpoint_regex\"] is None else None,\n",
    "    model_chkp_regex=CONFIG.get(\"swa_checkpoint_regex\"),\n",
    "    swa_sort_rule=CONFIG.get(\"swa_sort_rule\"),\n",
    "    n_swa_to_take=CONFIG.get(\"n_swa_models\", 3),\n",
    "    delete_prefix=CONFIG.get(\"delete_prefix\"),\n",
    "    prune_checkpoint_func=CONFIG.get(\"prune_checkpoint_func\")\n",
    ") for m_i in range(CONFIG[\"n_folds\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346bc17-431d-415d-a1c2-e198c64668c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ../logdirs/convnextv2_tiny_fcmae_ft_in22k_in1k_384_Exp_noamp_64bs_5sec_mixupP05_balancedSampler_lr1e4_CosineLREpoch50_ValV2_202xXcAddDataNoAddSecLabels_BackGroundSoundScapeP05_FocalLoss_FromPretrainFinalV1/onnx_ensem_3first_folds -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52abb97-e9ae-4704-b256-da95da65bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CONFIG.get(\"folds_to_onnx\") is not None:\n",
    "#     if isinstance(CONFIG[\"folds_to_onnx\"], int):\n",
    "        \n",
    "#         exportable_ensem = ONNXEnsemble(\n",
    "#             model_class=CONFIG[\"model_class\"],\n",
    "#             configs=[deepcopy(CONFIG['model_config']) for _ in CONFIG[\"folds\"][:CONFIG[\"folds_to_onnx\"]]],\n",
    "#             final_activation=CONFIG.get(\"final_activation\", None)\n",
    "#         )\n",
    "#         for model_id in range(len(exportable_ensem.models)):\n",
    "#             exportable_ensem.models[model_id].load_state_dict(model[model_id].state_dict())\n",
    "#         exportable_ensem.eval()\n",
    "#         convert_to_onnx(\n",
    "#             model_to_convert=exportable_ensem,\n",
    "#             sample_input=torch.randn(5, TRAIN_PERIOD * 32_000),\n",
    "#             base_path=f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_{CONFIG['folds_to_onnx']}first_folds\",\n",
    "#             use_fp16=CONFIG.get(\"use_fp16\", False),\n",
    "#             use_openvino=CONFIG.get(\"use_openvino\", False)\n",
    "#         )\n",
    "\n",
    "#     elif isinstance(CONFIG[\"folds_to_onnx\"], list):\n",
    "#         for fold_id in CONFIG[\"folds_to_onnx\"]:\n",
    "#             exportable_ensem = ONNXEnsemble(\n",
    "#                 model_class=CONFIG[\"model_class\"],\n",
    "#                 configs=[deepcopy(CONFIG['model_config'])],\n",
    "#                 final_activation=CONFIG.get(\"final_activation\", None)\n",
    "#             )\n",
    "#             # for model_id in range(len(exportable_ensem.models)):\n",
    "#             exportable_ensem.models[0].load_state_dict(model[fold_id].state_dict())\n",
    "            \n",
    "#             exportable_ensem.eval()\n",
    "#             convert_to_onnx(\n",
    "#                 model_to_convert=exportable_ensem,\n",
    "#                 sample_input=torch.randn(5, TRAIN_PERIOD * 32_000),\n",
    "#                 base_path=f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_fold{fold_id}\",\n",
    "#                 use_fp16=CONFIG.get(\"use_fp16\", False),\n",
    "#                 use_openvino=CONFIG.get(\"use_openvino\", False)\n",
    "#             )\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(f\"{type(CONFIG['folds_to_onnx'])} - unsupported type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72379cff-f673-4020-8105-41607cf68107",
   "metadata": {},
   "source": [
    "# Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c17c1f-7efe-41e6-9a2e-3285c81ef740",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_class = BirdsInference(\n",
    "    device=\"cuda\",\n",
    "    verbose_tqdm=True,\n",
    "    use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "    model_output_key=CONFIG[\"model_output_key\"],\n",
    "    aggregate_preds=CONFIG.get(\"aggregate_preds\", True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6bcf9a-e43d-4fe5-8228-0579b6a27240",
   "metadata": {},
   "source": [
    "# Val Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b158799-bea0-4a5f-a5fd-e0582c6c3734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CONFIG[\"run_validation\"]:\n",
    "    val_tgts, val_preds = inference_class.predict_val_loaders(\n",
    "        nn_models=model,\n",
    "        data_loaders=loader_val\n",
    "    )\n",
    "    if CONFIG.get(\"scored_birds_path\", None):\n",
    "        print(\"Extracting scored_bird_ids indices\")\n",
    "        scored_bird = load_json(CONFIG[\"scored_birds_path\"])\n",
    "        scored_bird_ids = [bird2id[el] for el in scored_bird]\n",
    "        val_tgts = [el[:,scored_bird_ids] for el in val_tgts]\n",
    "        val_preds = [el[:,scored_bird_ids] for el in val_preds]\n",
    "    cmaps = [\n",
    "        score_numpy(gt, pr) for gt, pr in zip(val_tgts, val_preds)\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        f\"Folds Roc Auc: {cmaps}\\n\"\n",
    "        f\"Mean Roc Auc: {np.mean(cmaps)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22541705-9c11-43e1-b7e7-e23af580a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(\"../predictions/\", EXP_NAME))\n",
    "np.save(\n",
    "    os.path.join(\"../predictions/\", EXP_NAME, \"tgts.npy\"),\n",
    "    np.array(val_tgts, dtype=object)\n",
    ")\n",
    "np.save(\n",
    "    os.path.join(\"../predictions/\", EXP_NAME, \"preds.npy\"),\n",
    "    np.array(val_preds, dtype=object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765f202-d013-49bd-bd7d-b161005bd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core = ov.Core()\n",
    "# model = core.read_model(model=f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_fold0_openvino_fp16/model_simpl.xml\")\n",
    "# compiled_model = core.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13939bdb-8fb1-4e72-8d60-b6eaf7e39ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CONFIG[\"run_validation\"]:\n",
    "#     val_tgts, val_preds = inference_class.predict_val_loaders(\n",
    "#         nn_models=[compiled_model],\n",
    "#         data_loaders=loader_val,\n",
    "#         is_openvino_model=True\n",
    "#     )\n",
    "#     if CONFIG.get(\"scored_birds_path\", None):\n",
    "#         print(\"Extracting scored_bird_ids indices\")\n",
    "#         scored_bird = load_json(CONFIG[\"scored_birds_path\"])\n",
    "#         scored_bird_ids = [bird2id[el] for el in scored_bird]\n",
    "#         val_tgts = [el[:,scored_bird_ids] for el in val_tgts]\n",
    "#         val_preds = [el[:,scored_bird_ids] for el in val_preds]\n",
    "#     cmaps = [\n",
    "#         score_numpy(gt, pr) for gt, pr in zip(val_tgts, val_preds)\n",
    "#     ]\n",
    "\n",
    "#     print(\n",
    "#         f\"Folds Roc Auc: {cmaps}\\n\"\n",
    "#         f\"Mean Roc Auc: {np.mean(cmaps)}\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ab37f-43dc-4b89-a547-681617b3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    EXP_NAME, \"\\n\"\n",
    "    f\"Folds Roc Auc: {cmaps}\\n\"\n",
    "    f\"Mean Roc Auc: {np.mean(cmaps)}\\n\"\n",
    "    f\"OOF Roc Auc: {score_numpy(np.concatenate(val_tgts), np.concatenate(val_preds))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d7354-942b-4c2f-835a-884bf0d1dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds[0].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7235f5-1e7f-4e0d-9568-78dda18d164a",
   "metadata": {},
   "source": [
    "# Search for Pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314297ea-fd7e-4948-99f9-af98588f41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_tgts = np.concatenate(val_tgts)\n",
    "all_val_preds = np.concatenate(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf9f77-d734-453a-a234-c7ca704c73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_treshes = np.arange(0.05 , 1.0 + 0.05, 0.05)\n",
    "all_scores = []\n",
    "for tresh in tqdm(all_treshes):\n",
    "    all_scores.append(f1_score(\n",
    "        all_val_tgts,\n",
    "        all_val_preds > tresh,\n",
    "        average=\"macro\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55f1fc-664a-4e0d-a615-ae0ec1d1a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(all_scores)\n",
    "best_tresh, best_score = all_treshes[best_idx], all_scores[best_idx]\n",
    "\n",
    "print(f\"Best Score = {best_score} and is reached on {best_tresh}\")\n",
    "\n",
    "plt.title(\"Macro F1 depending on tresh\")\n",
    "plt.plot(all_treshes, all_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7f5ca-909e-48b8-acf6-d2cacb136637",
   "metadata": {},
   "source": [
    "# Test Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab776f-b726-4633-a26e-ea3f85a75db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    test_preds, test_preds_long, test_dfidx, test_end = inference_class.predict_test_loader(\n",
    "        nn_models=model,\n",
    "        data_loader=loader_test\n",
    "    )\n",
    "    test_pred_df = compose_submission_dataframe(\n",
    "        probs=test_preds,\n",
    "        dfidxs=test_dfidx,\n",
    "        end_seconds=test_end,\n",
    "        filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "        bird2id=bird2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073afb3-6e5b-4a40-9b26-de6fa8ed6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd7503-e5c9-4169-8e81-6854db7b9b4d",
   "metadata": {},
   "source": [
    "# ONNX Test Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa5859-ff95-4efe-a50e-9b91dfe7175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_class_onnx = BirdsInference(\n",
    "    device=\"cpu\",\n",
    "    verbose_tqdm=True,\n",
    "    use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "    model_output_key=CONFIG[\"model_output_key\"],\n",
    "    use_compiled_fp16=CONFIG[\"use_compiled_fp16\"],\n",
    ")\n",
    "# onnx_model = ort.InferenceSession(\n",
    "#     # f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_2first_folds/model_simpl.onnx\"\n",
    "#     \"../logdirs/convnext_small_fb_in22k_ft_in1k_384_Exp_noamp_64bs_5sec_mixupP05_RandomFiltering_balancedSampler_Radamlr1e4_CosBatchLR1e6_Epoch50_SpecAugV1_FocalLoss_Full/onnx_ensem/model_simpl.onnx\"\n",
    "# )\n",
    "# core = ov.Core()\n",
    "# model = core.read_model(model=f\"../logdirs/convnext_small_fb_in22k_ft_in1k_384_Exp_noamp_64bs_5sec_mixupP05_RandomFiltering_balancedSampler_Radamlr1e4_CosBatchLR1e6_Epoch50_SpecAugV1_FocalLoss_Full/openvino_ensem/model_simpl.xml\")\n",
    "# compiled_model = core.compile_model(model=model, device_name=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6e56f-e08d-4611-80ec-013b315968fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_onnx, test_dfidx_onnx, test_end_onnx = inference_class_onnx.predict_test_loader(\n",
    "    nn_models=compiled_model,\n",
    "    data_loader=loader_test,\n",
    "    is_openvino_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89962ccb-280f-4513-8eb1-e95c8535675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx = compose_submission_dataframe(\n",
    "    probs=test_preds_onnx,\n",
    "    dfidxs=test_dfidx_onnx,\n",
    "    end_seconds=test_end_onnx,\n",
    "    filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "    bird2id=bird2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7d0a8-1bc1-4eff-918c-905c8f574113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61965eb3-77f9-4f1f-a2df-f7c034e3cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx_fp16 = pd.read_csv(\"temp_fp16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00072a23-bc88-415d-989d-64d22c7932aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx_fp16.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d7026-a2e5-461f-842d-fefd51612b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(test_pred_df_onnx_fp16.iloc[:,1:].values - test_pred_df_onnx.iloc[:,1:].values).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b97df7-6c6d-4c2d-bd3e-90a663574320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred_df_onnx.to_csv(\"temp_fp16.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ad67f-4c65-4cc1-84fe-e341ad7e4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_pred_df_onnx.iloc[:,1:].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3139ea0-58f7-4bc9-aa1f-28209387db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"run_test\"]:\n",
    "    inference_class_onnx = BirdsInference(\n",
    "        device=\"cpu\",\n",
    "        verbose_tqdm=True,\n",
    "        use_sigmoid=CONFIG[\"use_sigmoid\"],\n",
    "        model_output_key=CONFIG[\"model_output_key\"],\n",
    "        \n",
    "    )\n",
    "    onnx_model = ort.InferenceSession(\n",
    "        f\"../logdirs/{CONFIG['exp_name']}/onnx_ensem_2first_folds/model_simpl.onnx\"\n",
    "    )\n",
    "    test_preds_onnx, test_preds_long_onnx, test_dfidx_onnx, test_end_onnx = inference_class_onnx.predict_test_loader(\n",
    "        nn_models=onnx_model,\n",
    "        data_loader=loader_test,\n",
    "        is_onnx_model=True\n",
    "    )\n",
    "    test_pred_df_onnx = compose_submission_dataframe(\n",
    "        probs=test_preds_onnx,\n",
    "        dfidxs=test_dfidx_onnx,\n",
    "        end_seconds=test_end_onnx,\n",
    "        filenames=loader_test.dataset.df[loader_test.dataset.name_col].copy(),\n",
    "        bird2id=bird2id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fa245-3dbf-48c0-aacd-c5af2fa040be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84806a-be2d-442e-b132-f7bc8db644f0",
   "metadata": {},
   "source": [
    "# Map Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438a237-70d2-48c2-a9e5-32335718135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.get(\"check_inf_class\", False):\n",
    "    val_ds_check = WaveAllFileDataset(df=val_df[0], **{\n",
    "           \"root\": CONFIG[\"train_data_root\"],\n",
    "           \"label_str2int_mapping_path\": CONFIG[\"label_map_data_path\"],\n",
    "           \"n_cores\": 64,\n",
    "           \"use_audio_cache\": True,\n",
    "           \"test_mode\": True,\n",
    "           \"segment_len\": CONFIG[\"segment_len\"],\n",
    "           \"lookback\":CONFIG[\"lookback\"],\n",
    "           \"lookahead\":CONFIG[\"lookahead\"],\n",
    "            \"sample_id\": None,\n",
    "            \"late_normalize\": CONFIG[\"late_normalize\"],\n",
    "            \"step\": CONFIG[\"step\"],\n",
    "        }\n",
    "    )\n",
    "    val_loader_check = torch.utils.data.DataLoader(\n",
    "        val_ds_check,\n",
    "        **loader_config\n",
    "    )\n",
    "    \n",
    "    test_preds_check, test_preds_long_check, test_dfidx_check, test_end_check = inference_class.predict_test_loader(\n",
    "        nn_models=model,\n",
    "        data_loader=val_loader_check\n",
    "    )\n",
    "    test_preds_check_grouped = groupby_np_array(\n",
    "        groupby_f=test_dfidx_check,\n",
    "        array_to_group=test_preds_check,\n",
    "        apply_f=stack_and_max_by_samples,\n",
    "    )\n",
    "    print(np.allclose(\n",
    "        test_preds_check_grouped,\n",
    "        val_preds\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6d7a1-3079-4296-9f29-1ca6cae7506e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
